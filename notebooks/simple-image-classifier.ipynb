{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBqJ6nJFVZ3X"
      },
      "source": [
        "# Simple Image Classifier\n",
        "\n",
        "Beginner-friendly image classifier built with [PyTorch](https://pytorch.org) and CIFAR-10.\n",
        "\n",
        "<img alt=\"A photo of a man on an elephant with an ML-generated overlay showing objects in the frame\" src=\"../assets/preview.png\" width=450px>\n",
        "\n",
        "An image classifier is an ML model that recognizes objects in images. We can build image classifiers by feeding tens of thousands of labelled images to a neural network. Tools like PyTorch train these networks by evaluating their performance against the dataset.\n",
        "\n",
        "Let's build an image classifier that detects planes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. We'll download a dataset, configure a neural network, train a model, and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unx1wmtVVZ3Z"
      },
      "source": [
        "## Step 1: Download a dataset and preview images\n",
        "\n",
        "A model is only as good as its dataset.\n",
        "\n",
        "Training tools need lots of high-quality data to build accurate models. We'll use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) of 60,000 photos to build our image classifier. Get started by downloading the dataset with [`torchvision`](https://pytorch.org/vision/stable/datasets.html) and previewing a handful of images from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "VhRLQqtAVZ3a",
        "outputId": "0f936560-35c2-444f-d990-3b2869c022bc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "# Download testing data from open datasets.\n",
        "testing_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "# Hyper parameters\n",
        "batch_size = 10\n",
        "EPOCHS = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    training_data,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "    )\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_data,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2)\n",
        "\n",
        "# Our model will recognize these kinds of objects\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Grab images from our training data\n",
        "load_data_itr = iter(train_dataloader)\n",
        "imgs, lables = load_data_itr.next()\n",
        "\n",
        "print(classes[lables[0]])\n",
        "plt.imshow(np.transpose(imgs[0], (1, 2, 0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6c69D55R59l"
      },
      "source": [
        "## Step 2:Creating Models\n",
        "Now that we have our dataset, we need to set up a [convolutional neural network](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) for PyTorch. Our neural network will transform an image into a description.\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). We define the layers of the network\n",
        "in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxJC0nEIVZ3c",
        "outputId": "27e8deb2-b56c-495c-978e-8b87b6b66209"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define a convolutional neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.input_lay = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.headen1_lay = nn.Linear(in_features=120, out_features=84)\n",
        "        self.output_lay = nn.Linear(in_features=84, out_features=10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.input_lay(x))\n",
        "        x = F.relu(self.headen1_lay(x))\n",
        "        x = self.output_lay(x)\n",
        "        return x\n",
        "net = Net()\n",
        "\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)                    # things to try\n",
        "\n",
        "print(\"Your network is ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in net.parameters():\n",
        "    print(type(param), param.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BzajW1QVZ3c"
      },
      "source": [
        "# Step 3: Train the network and save model\n",
        "\n",
        "PyTorch trains our network by adjusting its parameters and evaluating its performance against our labelled dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg4kpwFqVZ3c",
        "outputId": "bcc5869d-cf40-4153-eafe-eefe108f58c7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} of {EPOCHS}\", leave=True, ncols=80)):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fun(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save our trained model\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDEP--ouVZ3d"
      },
      "source": [
        "# Step 4: Test the trained model\n",
        "\n",
        "Let's test our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "-1Wwi33_VZ3d",
        "outputId": "4e6aef64-ba46-4830-9b54-0d734e09e81e"
      },
      "outputs": [],
      "source": [
        "# Pick random photos from training set\n",
        "if load_data_itr == None:\n",
        "    load_data_itr = iter(test_dataloader)\n",
        "images, labels = load_data_itr.next()\n",
        "\n",
        "# Load our model\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Analyze images\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print(predicted)\n",
        "# Show results\n",
        "for i in range(batch_size):\n",
        "    # Add new subplot\n",
        "    plt.subplot(2, int(batch_size/2), i + 1)\n",
        "    # Plot the image\n",
        "    img = images[i]\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    # Add the image's label\n",
        "    color = \"green\"\n",
        "    label = classes[predicted[i]]\n",
        "    if classes[labels[i]] != classes[predicted[i]]:\n",
        "        color = \"red\"\n",
        "        label = \"(\" + label + \")\"\n",
        "    plt.title(label, color=color)\n",
        "\n",
        "plt.suptitle('Objects Found by Model', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdWY03PJVZ3d"
      },
      "source": [
        "# Step 5: Evaluate model accuracy\n",
        "\n",
        "Let's conclude by evaluating our model's overall performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq_18n0KVZ3d",
        "outputId": "84a06905-300f-4222-c68c-2679490ce171"
      },
      "outputs": [],
      "source": [
        "# Measure accuracy for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "tot_accuracy = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "# Print accuracy statistics\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "    tot_accuracy+=accuracy\n",
        "print(f\"total accuracy is {tot_accuracy/10}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
